{
    "summary": "The code generates permutations and combinations, initializes a list of numpy arrays, generates keys from shapes, retrieves values, calculates execution times for two methods, and proposes data classification using recursion.",
    "details": [
        {
            "comment": "The code defines functions for creating permutations of a given list of keys, sampling pairs from these permutations, and generating random permutations. It also checks if pairs are equal and sorts them based on hash values. The purpose seems to be creating various combinations of key pairs with some constraints like maximum sample size, sorting, or avoiding previous permutations.",
            "location": "\"/media/root/Prima/works/generated_docs/cf_doc/src/generic/vb_charec_bootstrap/mapdemo.py\":0-43",
            "content": "import numpy as np\n# mark with 1d 2d 3d and so on? inter-relationship.\n# use eval or nothing will happen.\n# extract sparse matrix?\nimport random\nimport itertools, time\nrng = random.SystemRandom()\ndef csampler(keys,max_sample=200):\n    pm = list(itertools.combinations(keys,r=2))\n    if len(pm) > max_sample:\n        # use generator instead?\n        pm = rng.sample(pm,max_sample)\n    return pm\ndef cprec(lk,l=0):\n    if l == 0:\n        lk -=1\n    if lk>0:\n        return cprec(lk-1,l+lk)\n    else:\n        return l\ndef tsort(a,b):\n    if (hash(a)>hash(b)):\n        return (a,b)\n    else:\n        return (b,a)\ndef nograt(keys,lk,prev):\n    # what about previous permutations?\n    # do it later: random pop?\n    r = np.random.permutation(keys)\n    r = [tsort(tuple(r[x]),keys[x]) for x in range(lk)]\n    r = filter(lambda x: not np.array_equal(x[0],x[1]),r)\n    prev = prev.union(set(r))\n    return prev\n# never know the upper bound.\n# this is slow.\ndef cs_mp(keys,max_sample=200):\n    # first, calculate the need for doing this.\n    lk = len(keys)"
        },
        {
            "comment": "This code defines several functions, including `cp` and `ip` calculations, `nograt`, `genkey`, `recget`, and `tgen`. The main functionality is related to generating keys from a tuple of shapes and getting values from a matrix using these keys. It also generates sparse matrices for individual pixels and groups them together.",
            "location": "\"/media/root/Prima/works/generated_docs/cf_doc/src/generic/vb_charec_bootstrap/mapdemo.py\":44-88",
            "content": "    cp = cprec(lk)\n    ip = int(2*max_sample/3)\n    idx = lk < ip\n    if cp > max_sample:\n        prev = set([])\n        while len(prev)<max_sample:\n            if idx:\n                prev = nograt(keys,lk,prev)\n            else:\n                prev = nograt(rng.sample(keys,ip),lk,prev)\n        for x in range(len(prev) - max_sample):\n            prev.pop()\n        return list(prev)\n    else:\n        return csampler(keys,max_sample)\ndef genkey(tup):\n    # check args length?\n    # max recursion 3?\n    base_list=[()]\n    for x in range(len(tup)):\n        base_list = [(*z,y) for z in base_list for y in range(tup[x])]\n    return base_list\ndef recget(a,x):\n    tar = a\n    for z in x:\n        tar = tar[z]\n    return tar\n# better use this in pypy? but how? use separate process or one single process? \n\"\"\"\na = np.array([0,0,0])\nb = np.array([0,1,1])\ne = np.array([1,1,1])\nd = np.array([0,0,1])\nc = np.array([0,0,1])\n\"\"\"\n# generate sparse matrix for individual pixels.\n# group them together.\ndef tgen(lst,a):\n    shape = a.shape\n    keys = genkey(shape)"
        },
        {
            "comment": "The code initializes a list of numpy arrays and uses it to generate keys and store data. It then generates a dictionary with keys as strings in the format \"a_0\", \"a_1\", etc., and creates an empty type generator dictionary. The code calls a function tgen to generate type-specific generators for each key in the dictionary and prints the results. Next, it calculates the shape of array 'a' and generates keys based on it. It measures the execution time for two different methods (cs_mp and csampler) that process the data and prints their output along with the execution times. The code then suggests printing the keys and using them to retrieve data from the list, but comments it out. Finally, it proposes classifying the data by creating a recursive function and storing the data in a dictionary structure.",
            "location": "\"/media/root/Prima/works/generated_docs/cf_doc/src/generic/vb_charec_bootstrap/mapdemo.py\":89-122",
            "content": "    typegen= {k:{0:[],1:[]} for k in keys}\n    for k in lst.keys():\n        f=lst[k]\n        for x in keys:\n            y=recget(f,x)\n            typegen[x][y].append(k)\n    return typegen\nlst = [np.array([x,y,z,e,f,g,h,i,j,k]) for x in range(2) for y in range(2) for z in range(2) for e in range(2) for f in range(2) for g in range(2) for h in range(2) for i in range(2) for j in range(2) for k in range(2)]\nlst = [np.array([x,y]) for x in lst for y in lst]\na=lst[0]\nlst = {\"a_{}\".format(k): lst[k] for k in range(len(lst))}\n#lst = {\"a\":a,\"b\":b,\"c\":c,\"d\":d,\"e\":e}\ntypegen=tgen(lst,a)\n#print(typegen)\nashp=genkey(a.shape)\nt0=time.time()\ncs = cs_mp(ashp,max_sample=5000)\n# still slower when not big enough.\nprint(cs,time.time()-t0)\nt0=time.time()\n# still slow?\ncs = csampler(ashp,max_sample=5000)\nprint(cs,time.time()-t0)\n# how do you map the logic? random plots?\n\"\"\"\nprint(keys)\n# use these keys to get data!\nfor dx in lst:\n    for x in keys:\n        print(x,recget(dx,x))\n\"\"\"\n# classify these things by what? better use a dict.\n# a recursive function?"
        }
    ]
}